{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# from cvnn import layers\n",
    "# import cvnn\n",
    "\n",
    "from pdb import set_trace\n",
    "# import tensorflow_datasets as tfds\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cmath\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2D, Conv2DTranspose, BatchNormalization, Dropout, Input, MaxPool2D, Activation\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, TimeDistributed, Flatten\n",
    "import gc\n",
    "# import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_size = 100\n",
    "path = \"../../../Dataset/sensor_domain/high_freq/100_breast_150_40/*\"\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_1000(y_true, y_pred):\n",
    "    mse = tf.norm((y_true - y_pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, test_size=0.25):\n",
    "    \n",
    "    ground_truth = []\n",
    "    sensor_data = []\n",
    "    count = 0\n",
    "    for filename in glob.glob(path):\n",
    "        mat = sio.loadmat(filename)\n",
    "        truth = mat[\"truth\"]\n",
    "        sensor = mat[\"sensor\"]\n",
    "        min_gt = mat[\"min_truth\"]\n",
    "        max_gt = mat[\"max_truth\"]\n",
    "        min_sensor = mat[\"min_sensor\"]\n",
    "        max_sensor = mat[\"max_sensor\"]\n",
    "        sensor_norm = mat[\"sensor_norm\"]\n",
    "        \n",
    "        \n",
    "        gt = (truth - min_gt) / (max_gt - min_gt)\n",
    "        # gt = np.expand_dims(gt, axis=0)\n",
    "        # sensor_norm = np.expand_dims(sensor_norm, axis=0)\n",
    "\n",
    "        temp = np.append(sensor_norm.real, sensor_norm.imag)\n",
    "        temp = np.reshape(temp, (ph_size*2, ph_size))\n",
    "        temp = np.asarray(temp)\n",
    "        ground_truth.append(gt)\n",
    "        sensor_data.append(temp)\n",
    "    temp_gt = []\n",
    "    temp_sens = []\n",
    "    for i in range(len(ground_truth)):\n",
    "        if np.isnan(ground_truth[i]).any() == False:\n",
    "            temp_gt.append(ground_truth[i])\n",
    "            temp_sens.append(sensor_data[i])\n",
    "    ground_truth = temp_gt\n",
    "    sensor_data = temp_sens\n",
    "    \n",
    "#     ground_truth = [i for i in ground_truth if np.isnan(i).any() == False]\n",
    "#     sensor_data = [i for i in sensor_data if np.isnan(i).any() == False]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(sensor_data,ground_truth, test_size=test_size, random_state=22)\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    # X_train = np.reshape(X_train, (np.asarray(X_train).shape[0], 1, np.asarray(X_train).shape[1]))\n",
    "    # X_test = np.reshape(X_test, (np.asarray(X_test).shape[0], 1, np.asarray(X_test).shape[1]))\n",
    "    # y_train = np.reshape(y_train, (np.asarray(y_train).shape[0], 1, np.asarray(y_train).shape[1]))\n",
    "    # y_test = np.reshape(y_test, (np.asarray(y_test).shape[0], 1, np.asarray(y_test).shape[1]))\n",
    "    # X_train = np.expand_dims(X_train, axis=-1)\n",
    "    # X_test = np.expand_dims(X_test, axis=-1)\n",
    "    # y_train = np.expand_dims(y_train, axis=-1)\n",
    "    # y_test = np.expand_dims(y_test, axis=-1)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = read_data(path, test_size=test_size)\n",
    "\n",
    "print(\"Data read : \\nX_train = {}\\ny_train = {}\\nX_test = {}\\ny_test = {}\".format(len(X_train), len(y_train), len(X_test), len(y_test)))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm():\n",
    "    model = tf.keras.Sequential()\n",
    "    # model.add(tf.keras.layers.Input(shape=(None,64,64)))\n",
    "    model.add(LSTM(4096,return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    # model.add(LSTM(4096))\n",
    "    model.add(Dense(ph_size*ph_size))\n",
    "\n",
    "    model.add(Reshape([ph_size, ph_size]))\n",
    "\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=1e-4, decay=1e-9)\n",
    "    sgd = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.8, nesterov=True, name=\"SGD\")\n",
    "    rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.00001, rho=0.9, momentum=0.0, epsilon=1e-07)\n",
    "\n",
    "    model.compile(loss = 'mse', optimizer='adam',metrics = ['accuracy'])\n",
    "    return model\n",
    "    # model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = model_lstm()\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_model = tf.keras.callbacks.ModelCheckpoint(\"Checkpoints/model2.hdf5\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "def decay_lr(epoch, lr):\n",
    "    if epoch % 10 == 0:\n",
    "        lr = lr - (lr*0.25)\n",
    "        return lr\n",
    "    return lr\n",
    "\n",
    "lr_decay = tf.keras.callbacks.LearningRateScheduler(decay_lr, verbose=1)\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    gc.collect()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7,\n",
    "                              patience=4, min_lr=1e-9, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = base_model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[lr_decay])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=413\n",
    "\n",
    "test = base_model.predict(np.expand_dims(X_test[x], axis=0))\n",
    "plt.imshow(test.squeeze(), cmap='gray')\n",
    "# plt.imsave(\"../3_pred.jpg\", test.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_test[x].squeeze(), cmap='gray')\n",
    "# plt.imsave(\"../3_gt.jpg\", y_test[x].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[x].squeeze(), cmap='gray')\n",
    "# plt.imsave(\"../3_gt.jpg\", y_test[x].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = test.squeeze()\n",
    "temp2 = y_test[x].squeeze()\n",
    "import math\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 1\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "psnr(temp1, temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model.save(\"Weights/lstm_model_1_4096_100epochs_40db_150fov_75\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = tf.keras.models.load_model(\"Weights/lstm_model_1_4096_100epochs_40db_150fov_75\")\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.models.load_model(\"Weights/lstm_model_1_4096_100epochs\")\n",
    "\n",
    "first_model = tf.keras.Model(\n",
    "    inputs = base_model.inputs,\n",
    "    outputs = base_model.layers[-1].output,\n",
    ")\n",
    "first_model.trainable = False\n",
    "second_model = tf.keras.Sequential(\n",
    "    [\n",
    "        first_model,\n",
    "        Reshape((100,100,1)),\n",
    "        Conv2D(16, kernel_size=3, activation='relu', padding='same'),\n",
    "        # Conv2D(32, kernel_size=5, activation='relu', padding='same'),\n",
    "        # Conv2D(64, kernel_size=5, activation='relu', padding='same'),\n",
    "        Conv2D(1, kernel_size=3, activation='relu', padding='same'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "second_model.compile(loss = 'mse', optimizer='adam',metrics = ['accuracy'])\n",
    "second_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = second_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "test1 = second_model.predict(np.expand_dims(X_test[x], axis=0))\n",
    "plt.imshow(test1.squeeze(), cmap='gray')\n",
    "# plt.imsave(\"../3_pred.jpg\", test.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=413\n",
    "test2 = base_model.predict(np.expand_dims(X_test[x], axis=0))\n",
    "plt.imshow(test2.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_test[x].squeeze(), cmap='gray')\n",
    "# plt.imsave(\"../3_gt.jpg\", y_test[x].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = test1.squeeze()\n",
    "temp2 = y_test[x].squeeze()\n",
    "import math\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 1\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "psnr(temp1, temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = test2.squeeze()\n",
    "temp2 = y_test[x].squeeze()\n",
    "import math\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 1\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "psnr(temp1, temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9cc78fe530da0142164923882eb6c93c6d14237cb9b1e774921e0d19f2eabfd7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf-hemanth-test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
