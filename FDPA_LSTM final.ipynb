{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# from cvnn import layers\n",
    "# import cvnn\n",
    "\n",
    "from pdb import set_trace\n",
    "# import tensorflow_datasets as tfds\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cmath\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.layers import Dense, Reshape, Conv2D, Conv2DTranspose, BatchNormalization, Dropout, Input, MaxPool2D, Activation\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, TimeDistributed, Flatten\n",
    "import gc\n",
    "# import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_NSR(Y_true, Y_pred):\n",
    "    signal = tf.norm(tf.reshape(Y_true, [tf.shape(Y_true)[0], -1]), axis=1)\n",
    "    noise = tf.norm(tf.reshape(Y_true - Y_pred, [tf.shape(Y_true)[0], -1]), axis=1)\n",
    "\n",
    "    return tf.math.reduce_mean(noise / signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_log_SNR(Y_true, Y_pred):\n",
    "    signal = tf.norm(tf.reshape(Y_true, [tf.shape(Y_true)[0], -1]), axis=1)\n",
    "    noise = tf.norm(tf.reshape(Y_true - Y_pred, [tf.shape(Y_true)[0], -1]), axis=1)\n",
    "\n",
    "    return tf.math.reduce_mean(20. * tf.math.log(signal / noise) / tf.math.log(10.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_size = 128\n",
    "path = \"../../../Dataset/sensor_domain/Final/dataset_300/*\"\n",
    "test_size = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_1000(y_true, y_pred):\n",
    "    mse = tf.norm((y_true - y_pred))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sensor_data(sensor):\n",
    "    sensor = sensor.flatten()\n",
    "    abs_sens = abs(sensor)\n",
    "    phase = np.asarray([cmath.phase(i) for i in sensor])\n",
    "    norm_abs = (abs_sens - min(abs_sens)) / (max(abs_sens) - min(abs_sens))\n",
    "    norm_phase = (phase - min(phase)) / (max(phase) - min(phase)) \n",
    "    norm_P = [cmath.rect(norm_abs[i], norm_phase[i]) for i in range(len(norm_abs))]\n",
    "    norm_P = np.reshape(np.asarray(norm_P), (ph_size//2, ph_size))\n",
    "    return norm_P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, test_size=0.25):\n",
    "    \n",
    "    ground_truth = []\n",
    "    sensor_data = []\n",
    "    count = 0\n",
    "    for filename in glob.glob(path):\n",
    "        mat = sio.loadmat(filename)\n",
    "        truth = mat[\"gt\"]\n",
    "        sensor = mat[\"P\"]\n",
    "\n",
    "        sensor = normalize_sensor_data(sensor)\n",
    "        \n",
    "        \n",
    "        # gt = (truth - min_gt) / (max_gt - min_gt)\n",
    "        # gt = np.expand_dims(gt, axis=0)\n",
    "        # sensor_norm = np.expand_dims(sensor_norm, axis=0)\n",
    "\n",
    "        temp = np.append(sensor.real, sensor.imag)\n",
    "\n",
    "        # P_min = np.amin(temp)\n",
    "        # P_max = np.amax(temp)\n",
    "\n",
    "        # sensor_norm = (temp - P_min) / (temp - P_min)\n",
    "        # temp = sensor_norm\n",
    "\n",
    "        temp = np.reshape(temp, (ph_size, ph_size))\n",
    "        temp = np.asarray(temp)\n",
    "        ground_truth.append(truth)\n",
    "        sensor_data.append(temp)\n",
    "    temp_gt = []\n",
    "    temp_sens = []\n",
    "    for i in range(len(ground_truth)):\n",
    "        if np.isnan(ground_truth[i]).any() == False:\n",
    "            temp_gt.append(ground_truth[i])\n",
    "            temp_sens.append(sensor_data[i])\n",
    "    ground_truth = temp_gt\n",
    "    sensor_data = temp_sens\n",
    "    \n",
    "#     ground_truth = [i for i in ground_truth if np.isnan(i).any() == False]\n",
    "#     sensor_data = [i for i in sensor_data if np.isnan(i).any() == False]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(sensor_data,ground_truth, test_size=test_size, random_state=22)\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    # X_train = np.reshape(X_train, (np.asarray(X_train).shape[0], 1, np.asarray(X_train).shape[1]))\n",
    "    # X_test = np.reshape(X_test, (np.asarray(X_test).shape[0], 1, np.asarray(X_test).shape[1]))\n",
    "    # y_train = np.reshape(y_train, (np.asarray(y_train).shape[0], 1, np.asarray(y_train).shape[1]))\n",
    "    # y_test = np.reshape(y_test, (np.asarray(y_test).shape[0], 1, np.asarray(y_test).shape[1]))\n",
    "    # X_train = np.expand_dims(X_train, axis=-1)\n",
    "    # X_test = np.expand_dims(X_test, axis=-1)\n",
    "    # y_train = np.expand_dims(y_train, axis=-1)\n",
    "    # y_test = np.expand_dims(y_test, axis=-1)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = read_data(path, test_size=test_size)\n",
    "\n",
    "print(\"Data read : \\nX_train = {}\\ny_train = {}\\nX_test = {}\\ny_test = {}\".format(len(X_train), len(y_train), len(X_test), len(y_test)))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm():\n",
    "    model = tf.keras.Sequential()\n",
    "    # model.add(tf.keras.layers.Input(shape=(None,64,64)))\n",
    "    model.add(LSTM(6144,return_sequences=False, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    # model.add(LSTM(4096,return_sequences=False))\n",
    "    # model.add(Dense(ph_size*ph_size//2))\n",
    "    model.add(Dense(ph_size*ph_size))\n",
    "\n",
    "    model.add(Reshape([ph_size, ph_size, 1]))\n",
    "    # model.add(Conv2D(128, kernel_size=5, st='same'))\n",
    "    # model.add(Conv2D(64, kernel_size=3, strides=1, padding='same'))rides=1, padding\n",
    "    model.add(Conv2D(1, kernel_size=3, strides=1, padding='same'))\n",
    "    model.add(Reshape([ph_size, ph_size]))\n",
    "\n",
    "    adam = tf.keras.optimizers.Adam(learning_rate=5e-3, decay=1e-9)\n",
    "    sgd = tf.keras.optimizers.SGD(learning_rate=0.001, momentum=0.8, nesterov=True, name=\"SGD\")\n",
    "    rmsprop = tf.keras.optimizers.RMSprop(learning_rate=0.00001, rho=0.9, momentum=0.0, epsilon=1e-07)\n",
    "\n",
    "    model.compile(loss = avg_NSR, optimizer='adam', metrics = [avg_log_SNR])\n",
    "    return model\n",
    "    # model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = model_lstm()\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_best_model = tf.keras.callbacks.ModelCheckpoint(\"Checkpoints/model_lstm_300.hdf5\", monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "def decay_lr(epoch, lr):\n",
    "    if epoch % 10 == 0 and epoch < 100:\n",
    "        lr = lr - (lr*0.2)\n",
    "        return lr\n",
    "    return lr\n",
    "\n",
    "lr_decay = tf.keras.callbacks.LearningRateScheduler(decay_lr, verbose=1)\n",
    "\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    gc.collect()\n",
    "\n",
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7,\n",
    "                              patience=4, min_lr=1e-9, verbose=1)\n",
    "\n",
    "class PredictionCallback(tf.keras.callbacks.Callback):    \n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if epoch % 5 == 0:\n",
    "      y_pred = self.model.predict(np.expand_dims(X_test[6], axis=0))\n",
    "      plt.figure()\n",
    "      plt.imshow(y_pred.squeeze(), cmap='gray')\n",
    "      plt.show()\n",
    "\n",
    "log_csv = CSVLogger('Logs/lstm_300.csv', separator=',', append=False) #### To store the train and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = base_model.fit(X_train, y_train, epochs=200, batch_size=32, validation_data=(X_test, y_test), callbacks=[lr_decay, PredictionCallback(), log_csv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model(\"Checkpoints/lstm_final_FDPA_LSTM copy\", compile=False)\n",
    "# model.compile(optimizer=Adam(learning_rate = 1e-3), loss=avg_NSR, metrics=[avg_log_SNR])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=613\n",
    "test = base_model.predict(np.expand_dims(X_test[x], axis=0))\n",
    "plt.imshow(test.squeeze(), cmap='gray')\n",
    "# plt.imsave(\"../3_pred.jpg\", test.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(y_test[x].squeeze(), cmap='gray')\n",
    "# plt.imsave(\"../3_gt.jpg\", y_test[x].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(X_test[x].squeeze(), cmap='gray')\n",
    "# plt.imsave(\"../3_gt.jpg\", y_test[x].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = test.squeeze()\n",
    "temp2 = y_test[x].squeeze()\n",
    "import math\n",
    "def psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return 100\n",
    "    PIXEL_MAX = 1\n",
    "    return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "psnr(temp1, temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.save(\"Checkpoints/lstm_final_FDPA_LSTM copy_300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = tf.keras.models.load_model(\"Weights/lstm_model_1_4096_100epochs_40db_150fov_75\")\n",
    "# base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = tf.keras.models.load_model(\"Weights/lstm_model_1_4096_100epochs\")\n",
    "\n",
    "# first_model = tf.keras.Model(\n",
    "#     inputs = base_model.inputs,\n",
    "#     outputs = base_model.layers[-1].output,\n",
    "# )\n",
    "# first_model.trainable = False\n",
    "# second_model = tf.keras.Sequential(\n",
    "#     [\n",
    "#         first_model,\n",
    "#         Reshape((100,100,1)),\n",
    "#         Conv2D(16, kernel_size=3, activation='relu', padding='same'),\n",
    "#         # Conv2D(32, kernel_size=5, activation='relu', padding='same'),\n",
    "#         # Conv2D(64, kernel_size=5, activation='relu', padding='same'),\n",
    "#         Conv2D(1, kernel_size=3, activation='relu', padding='same'),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# second_model.compile(loss = 'mse', optimizer='adam',metrics = ['accuracy'])\n",
    "# second_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = second_model.fit(X_train, y_train, epochs=20, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# test1 = second_model.predict(np.expand_dims(X_test[x], axis=0))\n",
    "# plt.imshow(test1.squeeze(), cmap='gray')\n",
    "# # plt.imsave(\"../3_pred.jpg\", test.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x=413\n",
    "# test2 = base_model.predict(np.expand_dims(X_test[x], axis=0))\n",
    "# plt.imshow(test2.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.imshow(y_test[x].squeeze(), cmap='gray')\n",
    "# # plt.imsave(\"../3_gt.jpg\", y_test[x].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp1 = test1.squeeze()\n",
    "# temp2 = y_test[x].squeeze()\n",
    "# import math\n",
    "# def psnr(img1, img2):\n",
    "#     mse = np.mean((img1 - img2) ** 2)\n",
    "#     if mse == 0:\n",
    "#         return 100\n",
    "#     PIXEL_MAX = 1\n",
    "#     return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "# psnr(temp1, temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp1 = test2.squeeze()\n",
    "# temp2 = y_test[x].squeeze()\n",
    "# import math\n",
    "# def psnr(img1, img2):\n",
    "#     mse = np.mean((img1 - img2) ** 2)\n",
    "#     if mse == 0:\n",
    "#         return 100\n",
    "#     PIXEL_MAX = 1\n",
    "#     return 20 * math.log10(PIXEL_MAX / math.sqrt(mse))\n",
    "\n",
    "# psnr(temp1, temp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, test_size=0.25):\n",
    "    \n",
    "    ground_truth = []\n",
    "    sensor_data = []\n",
    "    count = 0\n",
    "    for filename in glob.glob(path):\n",
    "        mat = sio.loadmat(filename)\n",
    "        truth = mat[\"gt\"]\n",
    "        sensor = mat[\"P\"]\n",
    "\n",
    "        # sensor = normalize_sensor_data(sensor)\n",
    "        \n",
    "        \n",
    "        # gt = (truth - min_gt) / (max_gt - min_gt)\n",
    "        # gt = np.expand_dims(gt, axis=0)\n",
    "        # sensor_norm = np.expand_dims(sensor_norm, axis=0)\n",
    "        temp = sensor\n",
    "        # print(temp.shape)\n",
    "        # temp = np.append(sensor.real, sensor.imag)\n",
    "\n",
    "        # P_min = np.amin(temp)\n",
    "        # P_max = np.amax(temp)\n",
    "\n",
    "        # sensor_norm = (temp - P_min) / (temp - P_min)\n",
    "        # temp = sensor_norm\n",
    "\n",
    "        # temp = np.reshape(temp, (ph_size, ph_size))\n",
    "        temp = np.asarray(temp)\n",
    "        ground_truth.append(truth)\n",
    "        sensor_data.append(temp)\n",
    "    temp_gt = []\n",
    "    temp_sens = []\n",
    "    for i in range(len(ground_truth)):\n",
    "        if np.isnan(ground_truth[i]).any() == False:\n",
    "            temp_gt.append(ground_truth[i])\n",
    "            temp_sens.append(sensor_data[i])\n",
    "    ground_truth = temp_gt\n",
    "    sensor_data = temp_sens\n",
    "    \n",
    "#     ground_truth = [i for i in ground_truth if np.isnan(i).any() == False]\n",
    "#     sensor_data = [i for i in sensor_data if np.isnan(i).any() == False]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(sensor_data,ground_truth, test_size=test_size, random_state=22)\n",
    "    X_train = np.asarray(X_train)\n",
    "    X_test = np.asarray(X_test)\n",
    "    y_train = np.asarray(y_train)\n",
    "    y_test = np.asarray(y_test)\n",
    "    # X_train = np.reshape(X_train, (np.asarray(X_train).shape[0], 1, np.asarray(X_train).shape[1]))\n",
    "    # X_test = np.reshape(X_test, (np.asarray(X_test).shape[0], 1, np.asarray(X_test).shape[1]))\n",
    "    # y_train = np.reshape(y_train, (np.asarray(y_train).shape[0], 1, np.asarray(y_train).shape[1]))\n",
    "    # y_test = np.reshape(y_test, (np.asarray(y_test).shape[0], 1, np.asarray(y_test).shape[1]))\n",
    "    # X_train = np.expand_dims(X_train, axis=-1)\n",
    "    # X_test = np.expand_dims(X_test, axis=-1)\n",
    "    # y_train = np.expand_dims(y_train, axis=-1)\n",
    "    # y_test = np.expand_dims(y_test, axis=-1)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data read : \n",
      "X_train = 9870\n",
      "y_train = 9870\n",
      "X_test = 4230\n",
      "y_test = 4230\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4230, 128, 64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = read_data(path, test_size=test_size)\n",
    "\n",
    "print(\"Data read : \\nX_train = {}\\ny_train = {}\\nX_test = {}\\ny_test = {}\".format(len(X_train), len(y_train), len(X_test), len(y_test)))\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tf-lstm')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c3f3af605c77ee5b7abe639f4e7df578f1f333f3134fb753e9fe6dbc466b2da7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
